{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c5b7a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gspread\n",
    "import pandas as pd\n",
    "import asyncio\n",
    "import aiohttp\n",
    "\n",
    "\n",
    "def clean_data1(circuit):\n",
    "    client = gspread.service_account(filename=\"/Users/lukehakso/kemp/skeleton/project/jobtracker.json\") # for macbook air\n",
    "\n",
    "    url = \"https://docs.google.com/spreadsheets/d/1M__pvslmhMRkXCl-7DEPc0PzvKj6qlgfc8antAd9hgI/edit#gid=223128104\"\n",
    "    # sandbox_url = \"https://docs.google.com/spreadsheets/d/1Mab3WIIMxUuFdjzayu1kYBbeIf_-fsLI89vgx9GPKho/edit#gid=223128104\n",
    "    HEADER_RANGE = \"A11:U11\"\n",
    "\n",
    "    wb = client.open_by_url(url)\n",
    "    first_circuit = wb.worksheet(circuit)\n",
    "\n",
    "    # Step 1: bring in the data & clean up\n",
    "\n",
    "    colnames = first_circuit.get_values(HEADER_RANGE)\n",
    "\n",
    "    colnames = colnames[0]\n",
    "\n",
    "    raw = pd.DataFrame(\n",
    "        first_circuit.get_values(\n",
    "            \"A14:T700\",\n",
    "        ),\n",
    "        columns=colnames[:-1],\n",
    "    )\n",
    "\n",
    "    munged_columns = [\n",
    "        x.lower()\n",
    "        .replace(\" \", \"_\")\n",
    "        .replace(\"/\", \"\")\n",
    "        .replace(\"#\", \"no\")\n",
    "        .replace(\"__\", \"_\")\n",
    "        for x in raw.columns\n",
    "    ]\n",
    "    raw.columns = munged_columns\n",
    "    raw = raw.rename(columns={\"squirt_boom\": \"requires_squirt_boom\"}).astype(\n",
    "        {\"requires_squirt_boom\": bool}\n",
    "    )\n",
    "\n",
    "    # df = raw.assign(unique_id=range(raw.shape[0]))\n",
    "    data = (\n",
    "        # was df.loc\n",
    "        raw.loc[\n",
    "            :,\n",
    "            [\n",
    "                \"full_address\",\n",
    "                \"projected_hours\",\n",
    "                \"requires_squirt_boom\",\n",
    "                \"status\",\n",
    "            ],\n",
    "        ]\n",
    "        .astype({\"requires_squirt_boom\": int})\n",
    "        .replace(\"Not Started\", False)\n",
    "        .replace(\"Done\", True)\n",
    "        .replace(\"In Process\", False)\n",
    "        # last two are temporary, need to ask what X and blank mean\n",
    "        .replace(\"X\", 1.25)\n",
    "        .replace(\"\", 1.25)\n",
    "    )\n",
    "    orig_data = (\n",
    "        raw.loc[\n",
    "            :,\n",
    "            [\n",
    "                \"site_no\",\n",
    "                \"address\",\n",
    "                \"work_description\",\n",
    "                \"owner_phone_comments\",\n",
    "                \"no_parks\",\n",
    "                \"nbw\",\n",
    "                \"projected_hours\",\n",
    "                \"flagging\",\n",
    "                \"requires_squirt_boom\",\n",
    "                \"merge\",\n",
    "                \"notes\",\n",
    "                \"also_clear_for\",\n",
    "                \"status\",\n",
    "            ],\n",
    "        ]\n",
    "        .replace(\"Not Started\", False)\n",
    "        .replace(\"Done\", True)\n",
    "        .replace(\"In Process\", False)\n",
    "        .replace(\"Hold/ Change in Contract\", True)\n",
    "    )\n",
    "\n",
    "    data = data[\n",
    "        data[\"status\"] == False\n",
    "    ]  # changes data to only sites that aren't completed\n",
    "    orig_data = orig_data[orig_data[\"status\"] == False]\n",
    "    return data, orig_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "87e2d68d-e670-4f98-9088-df42d885681c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import googlemaps\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import random\n",
    "\n",
    "knn = NearestNeighbors(n_neighbors=15)\n",
    "\n",
    "site_groups = []\n",
    "\n",
    "\n",
    "def cluster_sites1(target_work_hours: int, circuit: str) -> list[str]:\n",
    "    data, orig_data = clean_data1(circuit)\n",
    "    addresses, lats, lngs = get_address_coords(data)\n",
    "    stacked = stack_coords(lats, lngs)\n",
    "    stacked_copy = stacked.copy()\n",
    "    addresses_copy = addresses.copy()\n",
    "\n",
    "    for i in stacked_copy:\n",
    "        hours_sum = 0\n",
    "\n",
    "        neighbors_time_dict = {}\n",
    "\n",
    "        try:\n",
    "            neighbors_mat = get_neighbors(stacked_copy)\n",
    "\n",
    "        except ValueError:\n",
    "            # throws this error when there aren't enough sites left in stacked\n",
    "\n",
    "            print(\n",
    "                f\"\"\"\n",
    "            {len(stacked_copy)} remaining sites (not full {target_work_hours} hours):\n",
    "            {orig_data}\n",
    "            \"\"\"\n",
    "            )\n",
    "            break\n",
    "\n",
    "        for i in neighbors_mat:\n",
    "            # neighbors_mat is new every iteration, so indexes row 0\n",
    "            job_time = float(orig_data.iloc[i][\"projected_hours\"])\n",
    "            neighbors_time_dict[i] = job_time\n",
    "            # creates dict for site index and job_time\n",
    "\n",
    "        for hours in neighbors_time_dict.values():\n",
    "            hours_sum += hours\n",
    "            # get total hours in neighbors_mat\n",
    "        nbt_time_lst = list(neighbors_time_dict.values())\n",
    "\n",
    "        amount_over_target = hours_sum - target_work_hours\n",
    "\n",
    "        while True:\n",
    "            val_to_remove = nbt_time_lst[0]\n",
    "            # min(\n",
    "            # range(len(nbt_time_lst)),\n",
    "            # key=lambda i: abs(nbt_time_lst[i] - amount_over_target),\n",
    "            # )\n",
    "            # ]\n",
    "            # finds the hours values in neighbors_time_dict that is closest to the amount over target\n",
    "            if val_to_remove > amount_over_target and amount_over_target > 2.5:\n",
    "                for x in range(len(nbt_time_lst)):\n",
    "                    val = nbt_time_lst[x]\n",
    "                    if val < amount_over_target:\n",
    "                        val_to_remove = val\n",
    "                        break\n",
    "\n",
    "            if val_to_remove > amount_over_target:\n",
    "                break\n",
    "            \n",
    "            amount_over_target = amount_over_target - val_to_remove\n",
    "            site_to_remove = list(get_key(val_to_remove, neighbors_time_dict))\n",
    "            nbt_time_lst.remove(val_to_remove)\n",
    "            for i in site_to_remove:\n",
    "                # because multiple sites have same hour value, this loop keeps an error from being raised and tries again with another site\n",
    "                try:\n",
    "                    neighbors_mat.remove(i)\n",
    "                    break\n",
    "\n",
    "                except ValueError:\n",
    "                    pass\n",
    "\n",
    "        one_site_group = []\n",
    "        for idx in range(len(addresses_copy)):\n",
    "            if idx in neighbors_mat:\n",
    "                to_add = orig_data.iloc[idx].tolist()\n",
    "                if to_add[4]:\n",
    "                    to_add[4] = \"Yes\"\n",
    "                if not to_add[4]:\n",
    "                    to_add[4] = \"\"\n",
    "\n",
    "                if to_add[5]:\n",
    "                    to_add[5] = \"Yes\"\n",
    "                if not to_add[5]:\n",
    "                    to_add[5] = \"\"\n",
    "\n",
    "                if to_add[7]:\n",
    "                    to_add[7] = \"Yes\"\n",
    "                if not to_add[7]:\n",
    "                    to_add[7] = \"\"\n",
    "\n",
    "                if to_add[8]:\n",
    "                    to_add[8] = \"Yes\"\n",
    "                if not to_add[8]:\n",
    "                    to_add[8] = \"\"\n",
    "\n",
    "                if to_add[9]:\n",
    "                    to_add[9] = \"Yes\"\n",
    "                if not to_add[9]:\n",
    "                    to_add[9] = \"\"\n",
    "\n",
    "                del to_add[12]\n",
    "\n",
    "                one_site_group.append(to_add)\n",
    "\n",
    "        addresses_copy = [\n",
    "            ele for idx, ele in enumerate(addresses_copy) if idx not in neighbors_mat\n",
    "        ]\n",
    "        orig_data = orig_data.reset_index(drop=True)\n",
    "        orig_data = orig_data.drop(neighbors_mat)\n",
    "\n",
    "        stacked_copy = [\n",
    "            ele for idx, ele in enumerate(stacked_copy) if idx not in neighbors_mat\n",
    "        ]\n",
    "\n",
    "        site_groups.append(one_site_group)\n",
    "\n",
    "    # return clean(site_groups)\n",
    "    return site_groups\n",
    "\n",
    "\n",
    "def get_key(val, neighbors_time_dict):\n",
    "    for key, value in neighbors_time_dict.items():\n",
    "        if val == value:\n",
    "            yield key\n",
    "\n",
    "\n",
    "def clean(site_groups):\n",
    "    clean_site_groups = []\n",
    "\n",
    "    for i in site_groups:\n",
    "        groups = [x[0] for x in i]\n",
    "        clean_site_groups.append(groups)\n",
    "    return clean_site_groups\n",
    "\n",
    "\n",
    "def get_address_coords(data):\n",
    "    gmaps = googlemaps.Client(key=\"AIzaSyCe-hRSpX1tm2kND1AhL5ueIPd-rduvcaE\")\n",
    "    df = data.loc[:, \"full_address\"]\n",
    "    df = pd.DataFrame(df)\n",
    "    addresses = df.values.tolist()\n",
    "\n",
    "    lats = []\n",
    "    lngs = []\n",
    "\n",
    "    addresses = [x for x in addresses if x != [\"\"]]\n",
    "\n",
    "    for x in range(0, len(addresses)):\n",
    "        lats.append(random.random())\n",
    "        lngs.append(random.random())\n",
    "        #should not go into deployed version\n",
    "        #only for testing\n",
    "    \n",
    "    return addresses, lats, lngs\n",
    "\n",
    "\n",
    "def stack_coords(lats, lngs):\n",
    "    x = np.array(lngs)\n",
    "    y = np.array(lats)\n",
    "    stacked = np.dstack((x, y))\n",
    "    stacked = stacked[0]\n",
    "    return stacked\n",
    "\n",
    "def get_neighbors(points):\n",
    "    knn.fit(points)\n",
    "    distance_mat, neighbors_mat = knn.kneighbors(points)\n",
    "    neighbors_mat = list(\n",
    "        reversed(neighbors_mat[0])\n",
    "    )  # reversed so closest pt comes last\n",
    "    return neighbors_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "69821d09-395b-4c90-90c2-937b7cd1b7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            14 remaining sites (not full 10 hours):\n",
      "               site_no               address  \\\n",
      "1      346       2547 NE 98TH ST   \n",
      "2      368   10361 FISCHER PL NE   \n",
      "4      378      2821 NE 105TH ST   \n",
      "5      380      2827 NE 105TH ST   \n",
      "6      397  10038 RAVENNA AVE NE   \n",
      "12     483       3238 NE 94TH ST   \n",
      "13     491       3015 NE 92ND ST   \n",
      "14     499       3221 NE 92ND ST   \n",
      "15     507       9025 32ND AVENE   \n",
      "19     538       3019 NE 87TH ST   \n",
      "20     539       3011 NE 87TH ST   \n",
      "21     633       3855 NE 86TH ST   \n",
      "22     635       3804 NE 87TH ST   \n",
      "23     638       3854 NE 87TH ST   \n",
      "\n",
      "                                     work_description owner_phone_comments  \\\n",
      "1                             ST DOGWOOD / CLEAR POLE                        \n",
      "2   TTS CEDARS, HEMLOCKS, TOP DEAD HEMLOCK, BELOW ...                        \n",
      "4                                   TTS ALL ON 105TH                         \n",
      "5                 TTS ALL ALONG DRIVEWAY / CLEAR POLE                        \n",
      "6                TTS ALL FOR P-P  TRIPLEX IN BACKYARD                        \n",
      "12                                       TTS CHERRIES                        \n",
      "13                           TT  DECIDUOUS CLEAR POLE                        \n",
      "14                                             ST OAK                        \n",
      "15                                           TT PINES                        \n",
      "19                                           ST CEDAR                        \n",
      "20                                 ST FIR TT PHOTINIA                        \n",
      "21                 TT 2 CHERRIES ST SPRUCE BOTH SIDES                        \n",
      "22                                   TT APPLE ON 38TH                        \n",
      "23                          ST FIR ON 40TH CLEAR POLE                        \n",
      "\n",
      "   no_parks nbw projected_hours flagging  requires_squirt_boom merge notes  \\\n",
      "1                          0.75                          False               \n",
      "2                          2.50        X                 False               \n",
      "4                          2.50        X                 False               \n",
      "5                          3.25                           True               \n",
      "6                          3.00                          False               \n",
      "12                         0.75                          False               \n",
      "13                         0.50                          False               \n",
      "14                         1.00                          False               \n",
      "15                         1.00                          False               \n",
      "19                         1.00                          False               \n",
      "20                         1.00                          False               \n",
      "21                         2.00                          False               \n",
      "22                         0.75                          False               \n",
      "23                         2.00                          False               \n",
      "\n",
      "   also_clear_for  status  \n",
      "1                   False  \n",
      "2                   False  \n",
      "4                   False  \n",
      "5                   False  \n",
      "6                   False  \n",
      "12                  False  \n",
      "13                  False  \n",
      "14                  False  \n",
      "15                  False  \n",
      "19                  False  \n",
      "20                  False  \n",
      "21                  False  \n",
      "22                  False  \n",
      "23                  False  \n",
      "            \n"
     ]
    }
   ],
   "source": [
    "site_groups = cluster_sites1(10, \"2615 - North\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c9f92013-1577-4338-9e8e-e5b0dfbcd7bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['0.75',\n",
       "  '1.00',\n",
       "  '0.25',\n",
       "  '1.00',\n",
       "  '0.75',\n",
       "  '0.75',\n",
       "  '1.00',\n",
       "  '0.75',\n",
       "  '0.75',\n",
       "  '0.75',\n",
       "  '3.00'],\n",
       " ['16.00'],\n",
       " ['0.75', '1.00', '3.00', '1.00', '0.75', '2.00', '2.00'],\n",
       " ['1.50', '1.00', '1.00', '2.00', '3.00', '0.75', '0.75', '0.75'],\n",
       " ['1.75', '1.50', '1.00', '2.50', '0.50', '1.00', '1.00', '2.00', '0.75'],\n",
       " ['1.00', '0.75', '0.25', '2.00', '0.50', '1.75', '2.00', '3.00'],\n",
       " ['1.25',\n",
       "  '1.00',\n",
       "  '0.75',\n",
       "  '0.50',\n",
       "  '0.75',\n",
       "  '1.00',\n",
       "  '2.00',\n",
       "  '1.00',\n",
       "  '1.00',\n",
       "  '1.00'],\n",
       " ['4.00', '2.00', '2.00', '0.50', '1.00', '0.75'],\n",
       " ['1.75', '1.00', '2.00', '1.00', '0.75', '1.25', '0.75', '2.00'],\n",
       " ['1.00', '1.75', '3.00', '1.00', '2.00', '1.50'],\n",
       " ['1.00', '2.00', '3.00', '3.00', '1.25', '0.50'],\n",
       " ['1.00', '1.00', '2.00', '0.50', '0.75', '2.00', '0.75', '1.00', '1.00'],\n",
       " ['2.00', '1.00', '1.00', '1.50', '2.00', '1.00', '2.00'],\n",
       " ['3.00', '1.00', '1.00', '3.00', '1.00', '1.00', '0.75'],\n",
       " ['3.00', '0.75', '1.00', '0.75', '1.00', '3.25', '2.00'],\n",
       " ['2.00', '0.00', '1.00', '2.00', '3.25', '0.50', '1.00', '1.00'],\n",
       " ['1.25', '10.00'],\n",
       " ['1.00', '0.75', '3.00', '2.00', '2.00', '0.25', '1.50'],\n",
       " ['1.00', '2.25', '4.00', '2.00', '1.00'],\n",
       " ['2.00', '1.25', '0.75', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00'],\n",
       " ['0.75', '1.00', '7.00', '1.25'],\n",
       " ['1.00', '2.25', '2.00', '0.50', '1.00', '1.00', '1.00', '2.00'],\n",
       " ['2.00',\n",
       "  '0.50',\n",
       "  '1.25',\n",
       "  '0.50',\n",
       "  '1.00',\n",
       "  '0.00',\n",
       "  '2.00',\n",
       "  '3.00',\n",
       "  '0.75',\n",
       "  '0.75']]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hours = []\n",
    "for i in site_groups:\n",
    "    hours.append([x[6] for x in i])\n",
    "hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc3631a9-2482-45eb-8111-31042752301d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "knn = NearestNeighbors(n_neighbors=2)\n",
    "stacked_copy = [[1,2], [3,5],[5,4], [6,9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba16c614-5fe3-44e9-94e4-52892c9b4057",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbors(points):\n",
    "    knn.fit(points)\n",
    "    distance_mat, neighbors_mat = knn.kneighbors(points)\n",
    "    neighbors_mat = list(\n",
    "        reversed(neighbors_mat[0])\n",
    "    )  # reversed so closest pt comes last\n",
    "    return neighbors_mat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".kwenv",
   "language": "python",
   "name": ".kwenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
